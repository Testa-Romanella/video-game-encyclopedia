{"id": 880103, "slug": "top-down-interpretability-through-eigenspectra", "name": "Top-Down Interpretability Through Eigenspectra", "name_original": "Top-Down Interpretability Through Eigenspectra", "description": "<p>Random matrix theory (RMT) offers a host of tools to make sense of neural networks. In this paper, we look at the heavy-tailed random matrix theory developed by Martin and Mahoney (2021). From the spectrum of eigenvalues, it\u2019s possible to derive generalization metrics that are independent of data, and to make decompose the training process into five unique phases. Additionally, the theory predicts and tests a key form learning bias known as \u201cself-regularization.\u201d In this paper, we extend the results from computer vision to language models, finding many similarities and a few potentially meaningful differences. This provides a glimpse of what more \u201ctop-down\u201d interpretability approaches might accomplish: from a deeper understanding of the training process and path-dependence to inductive bias and generalization.</p>", "metacritic": null, "released": "2022-11-13", "tba": false, "updated": "2022-11-14T07:57:10", "background_image": "https://media.rawg.io/media/screenshots/9d4/9d4004c83e796f9c50c721620b3b147e.jpg", "website": "", "rating": 0.0, "rating_top": 0, "added_by_status": null, "playtime": 0, "achievements_count": 0, "ratings_count": 0, "suggestions_count": 41, "game_series_count": 0, "reviews_count": 0, "platforms": ["PC"], "developers": ["jhoogland"], "genres": [], "publishers": [], "esrb_rating": null}