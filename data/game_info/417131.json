{"id": 417131, "slug": "legend-of-renai", "name": "Legend of Ren'AI", "name_original": "Legend of Ren'AI", "description": "<p>Legend of Ren'AI is an experimental visual novel that was created by automatically translating text that was generated by an artificial neural network into Ren'Py scripts. The neural network was fine-tuned with scripts from Legend of Everything, whose characters and settings are featured in this game.<br/></p>\r\nOptional: Generate new scripts\r\n<p>[For advanced users] Legend of Ren'AI already comes with a number of pre-generated scripts, but if you want to generate new ones, open this Google Colab notebook and follow the instructions.<br/></p>\r\nHow this game was made\r\n<p><em>It's not necessary to read this part to be able to play the game. Feel free to skip to the Download section below.</em><br/></p>\n<p>The scripts in this game were generated using OpenAI's GPT-2 language model that had been fine-tuned using scripts from my latest game Legend of Everything, which was made using the popular visual novel engine Ren'Py. To be clear, when I say \"script,\" I'm referring to the source code that can be executed by the Ren'Py engine, so the GPT-2 model was essentially trained to produce text that resembles a computer program. However, the scripts that were used to train the neural network had been pre-processed to only contain a small subset of available Ren'Py commands, in order to make the code that the GPT-2 model would generate more predictable.</p>\n<p>For example, Legend of Everything has a lot of action scenes that require rather complicated code to move sprites around, show visual effects, etc. These parts of the code were automatically removed by a pre-processing program before they were fed to the model for training.</p>\n<p>Furthermore, the dataset only included scenes from the main story. Those who have played Legend of Everything might know that the game contains a number of optional scenes called \"QED talks,\" in which certain characters discuss some scientific topics in detail. These scenes weren't included in the training dataset because they're quite different from the rest of the game.</p>\n<p>The GPT-2 model that was used for this project is the \"medium\"-sized model, with 355 million parameters. (The largest GPT-2 model contains 1.5 billion parameters and requires a massive amount of computing power to work with.) Fine-tuning was done using gpt-2-simple's accompanying Google Colab notebook.</p>\n<p>After it was fine-tuned, the GPT-2 model could generate Ren'Py code that is mostly correct, but not quite ready to be added to the game. The generated text had to be post-processed by another program to add some additional commands and automatically make corrections to ensure that the final script is valid Ren'Py code. This process was done programmatically. \u00a0<em>There was no manual curation or manual fixes</em> in producing the scripts in Legend of Ren'AI.</p>\n<p>Finally, what about in-game choices? Well, the GPT-2 model wasn't trained to create branching narratives. The script generation software simply picks one of the protagonist's lines in the generated text and discards it along with the rest of the text. And then, it would prompt the GPT-2 model to continue from that point onward several times, each time generating a unique\u2014but equally nonsensical\u2014continuation of the story.<br/></p>", "metacritic": null, "released": "2020-03-04", "tba": false, "updated": "2020-03-06T03:04:49", "background_image": "https://media.rawg.io/media/screenshots/e93/e939df46aa4fc3f3385d6b38dfbef739.jpg", "website": "", "rating": 0.0, "rating_top": 0, "added_by_status": null, "playtime": 0, "achievements_count": 0, "ratings_count": 0, "suggestions_count": 216, "game_series_count": 0, "reviews_count": 0, "platforms": ["PC", "macOS", "Linux"], "developers": ["Kidalang"], "genres": [], "publishers": [], "esrb_rating": null}